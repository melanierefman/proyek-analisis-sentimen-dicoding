# -*- coding: utf-8 -*-
"""Scraping Data Ulasan Shopee.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1o2TJFOU2vcc75Rt88qZHyTsTs7LKGP9W
"""

import re
import requests
import pandas as pd
import time

# URL pertama
url1 = 'https://shopee.co.id/Hongzhuo-Cookware-Panci-Set-Wajan-Penggorengan-Spatula-Set-Isi-13Pcs-1-Set-Frypan-Saucepan-i.263338737.6195214203?sp_atk=531ecbc7-56d8-4312-8b79-8ee193ad5d12&xptdk=531ecbc7-56d8-4312-8b79-8ee193ad5d12'

# URL kedua
url2 = 'https://shopee.co.id/Hongzhuo-Panci-Set-Isi-6pcs-Pot-Series-Panci-Terlengkap-dengan-Tutupan-dan-Spatula-i.263338737.16914282677?sp_atk=4fad4907-5898-4cc2-9085-4ff4ae943a3c'

# URL ketiga
url3 = 'https://shopee.co.id/Hongzhuo-Panci-Sop-22cm-Enamel-Stainless-Soup-Pot-Panci-Susu-i.263338737.16027427773?sp_atk=e15422b7-2e2d-4b2c-b264-c37f1dde5d91'

# URL baru 1
url4 = 'https://shopee.co.id/product/263338737/23740919762?d_id=a41fb&uls_trackid=51enm3b700du&utm_content=2v3yEjchZCvPqKsTgtHnRqGasVbV&is_from_login=true'

# URL baru 2
url5 = 'https://shopee.co.id/product/263338737/18244857852?d_id=a41fb&uls_trackid=51enm85900ug&utm_content=2v3yEjchZCz56QEBkd5vL7Vuh7KM'

# URL baru 3
url6 = 'https://shopee.co.id/product/263338737/24601642262?d_id=a41fb&uls_trackid=51enm9cb011m&utm_content=2v3yEjchZD6ejmeSMYxY4M2nK95y'

# Extract shop_id dan item_id dari URL pertama
r1 = re.search(r'i\.(\d+)\.(\d+)', url1)
shop_id1, item_id1 = r1[1], r1[2]

# Extract shop_id dan item_id dari URL kedua
r2 = re.search(r'i\.(\d+)\.(\d+)', url2)
shop_id2, item_id2 = r2[1], r2[2]

# Extract shop_id dan item_id dari URL ketiga
r3 = re.search(r'i\.(\d+)\.(\d+)', url3)
shop_id3, item_id3 = r3[1], r3[2]

# Extract shop_id dan item_id dari URL baru 1
r4 = re.search(r'product/(\d+)/(\d+)', url4)
shop_id4, item_id4 = r4[1], r4[2]

# Extract shop_id dan item_id dari URL baru 2
r5 = re.search(r'product/(\d+)/(\d+)', url5)
shop_id5, item_id5 = r5[1], r5[2]

# Extract shop_id dan item_id dari URL baru 3
r6 = re.search(r'product/(\d+)/(\d+)', url6)
shop_id6, item_id6 = r6[1], r6[2]

ratings_url = 'https://shopee.co.id/api/v2/item/get_ratings?filter=0&flag=1&itemid={item_id}&limit=20&offset={offset}&shopid={shop_id}&type=0'

headers = {
    "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/117.0.0.0 Safari/537.36",
    "Referer": url1
}

cookies = {
    # Salin cookie dari browser
    "SPC_EC": "cookie_value",
    "SPC_R_T_ID": "cookie_value",
}

offset = 0
max_reviews = 15000
total_reviews = 0
d = {'username': [], 'rating': [], 'comment': []}

# Fungsi untuk scraping data dari satu URL dengan kondisi rating 3-1
def scrape_reviews(shop_id, item_id, offset, min_rating=1, max_rating=3):
    global total_reviews
    while total_reviews < max_reviews:
        response = requests.get(
            ratings_url.format(shop_id=shop_id, item_id=item_id, offset=offset),
            headers=headers,
            cookies=cookies
        )
        print(f"Fetching offset {offset} - Status Code: {response.status_code}")

        if response.status_code != 200:
            print("Failed to fetch data")
            break

        data = response.json()
        if "data" not in data or "ratings" not in data["data"]:
            print("No more data or key 'data' not found")
            break

        for rating in data["data"]["ratings"]:
            # Cek jika ada komentar dan rating dalam rentang yang ditentukan
            rating_value = rating.get('rating_star', 0)
            comment = rating.get('comment', None)
            if comment and min_rating <= rating_value <= max_rating:
                d['username'].append(rating.get('author_username', 'N/A'))
                d['rating'].append(rating_value)
                d['comment'].append(comment)
                total_reviews += 1

        print(f"Total reviews scraped so far: {total_reviews}")

        if len(data["data"]["ratings"]) < 20 or total_reviews >= max_reviews:
            break

        offset += 20
        time.sleep(2)

# Scraping untuk URL pertama (semua ulasan dengan komentar)
def scrape_reviews_all(shop_id, item_id, offset):
    global total_reviews
    while total_reviews < max_reviews:
        response = requests.get(
            ratings_url.format(shop_id=shop_id, item_id=item_id, offset=offset),
            headers=headers,
            cookies=cookies
        )
        print(f"Fetching offset {offset} - Status Code: {response.status_code}")

        if response.status_code != 200:
            print("Failed to fetch data")
            break

        data = response.json()
        if "data" not in data or "ratings" not in data["data"]:
            print("No more data or key 'data' not found")
            break

        for rating in data["data"]["ratings"]:
            # Cek jika ada komentar
            comment = rating.get('comment', None)
            if comment:  # Hanya ambil jika ada komentar
                d['username'].append(rating.get('author_username', 'N/A'))
                d['rating'].append(rating.get('rating_star', 0))
                d['comment'].append(comment)
                total_reviews += 1

        print(f"Total reviews scraped so far: {total_reviews}")

        if len(data["data"]["ratings"]) < 20 or total_reviews >= max_reviews:
            break

        offset += 20
        time.sleep(2)  # Tambahkan jeda untuk menghindari deteksi bot

# Mulai scraping untuk URL pertama, kedua, ketiga, dan tiga URL baru
scrape_reviews_all(shop_id1, item_id1, offset)
scrape_reviews(shop_id2, item_id2, offset, 1, 3)
scrape_reviews(shop_id3, item_id3, offset, 1, 3)
scrape_reviews(shop_id4, item_id4, offset, 1, 3)
scrape_reviews(shop_id5, item_id5, offset, 1, 3)
scrape_reviews(shop_id6, item_id6, offset, 1, 3)

# Simpan ke CSV
df = pd.DataFrame(d)
df.to_csv("shopee_reviews_filtered.csv", index=False)
print(f"Saved {len(d['username'])} reviews to 'shopee_reviews_filtered.csv'")